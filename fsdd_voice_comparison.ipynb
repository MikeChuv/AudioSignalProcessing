{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.feature\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.stats\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "import sklearn.metrics\n",
    "import sklearn\n",
    "from scipy.spatial.distance import  mahalanobis\n",
    "import cv2\n",
    "\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from FSDDComparisonHelp import FSDD, getMFCC, getTwoMFCCs, showMFCC, compareFeatures\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "\n",
    "# plt.style.use(\"classic\")\n",
    "# plt.style.use(\"bmh\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMFCCs(y, sr):\n",
    "    return librosa.feature.mfcc(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            n_mfcc=12,\n",
    "            dct_type=3,\n",
    "            n_fft=512,\n",
    "            hop_length=256\n",
    "        )\n",
    "\n",
    "def getFeatureList(speakerFilesList : list):\n",
    "    featureList = []\n",
    "    for file in speakerFilesList:\n",
    "        y, sr = librosa.load(file)\n",
    "        # S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=80, fmax=8000)\n",
    "        S = extractMFCCs(y, sr)\n",
    "        # S = librosa.feature.mfcc(y=y, sr=sr, dct_type=3)\n",
    "        featureList.append(S)\n",
    "    return featureList\n",
    "\n",
    "def getDeltasList(speakerFilesList : list):\n",
    "    featureList = []\n",
    "    for file in speakerFilesList:\n",
    "        y, sr = librosa.load(file)\n",
    "        S = extractMFCCs(y, sr)\n",
    "        S = sklearn.preprocessing.scale(S, axis=1)\n",
    "        S = librosa.feature.delta(S, width=3)\n",
    "        featureList.append(S)\n",
    "    return featureList\n",
    "\n",
    "def trimFeatures(collection : list):\n",
    "    newCollection = []\n",
    "    minLen = min(min([feature.shape[1] for feature in featureList]) for featureList in collection)\n",
    "    for featureList in collection:\n",
    "        newFeatureList = [feature[:, :minLen] for feature in featureList]\n",
    "        newCollection.append(newFeatureList)\n",
    "    return newCollection\n",
    "\n",
    "def meanDist(features, gmm):\n",
    "    rlistA = []\n",
    "    for el in features:\n",
    "        x = el\n",
    "        means = np.squeeze(gmm.means_)\n",
    "        cov = np.squeeze(gmm.covariances_)\n",
    "        r = np.sqrt((x - means).T @ np.linalg.inv(cov) @ (x - means)) # mahalanobis(x, means, np.linalg.inv(cov))\n",
    "        rlistA.append(r)\n",
    "    return np.mean(rlistA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nicolas', 'theo', 'lucas', 'george', 'jackson', 'yweweler']\n",
      "george\n",
      "yweweler\n"
     ]
    }
   ],
   "source": [
    "spkA = 3\n",
    "spkB = 5\n",
    "fsdd = FSDD('../Datasets/FSDD/recordings')\n",
    "print(fsdd.speakers)\n",
    "# spkA = 1\n",
    "# spkB = 3\n",
    "filesA, filesB = fsdd.getFilesForDigit(0, spkA=spkA, spkB=spkB)\n",
    "print(fsdd.speakers[spkA])\n",
    "print(fsdd.speakers[spkB])\n",
    "\n",
    "mfccsA = getFeatureList(filesA)\n",
    "mfccsB = getFeatureList(filesB)\n",
    "mfccsA, mfccsB = trimFeatures([mfccsA, mfccsB])\n",
    "\n",
    "deltasA = getDeltasList(filesA)\n",
    "deltasB = getDeltasList(filesB)\n",
    "deltasA, deltasB = trimFeatures([deltasA, deltasB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 24)\n",
      "(1080, 24)\n",
      "(120, 24)\n",
      "(120, 24)\n",
      "Means\n",
      "(1, 24)\n",
      "(1, 24)\n",
      "Covariances\n",
      "(1, 24, 24)\n",
      "(1, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "featuresListA = []\n",
    "for spkFeatures in zip(mfccsA, deltasA):\n",
    "    f = np.vstack(spkFeatures)\n",
    "    featuresListA.append(f)\n",
    "\n",
    "\n",
    "featuresListB = []\n",
    "for spkFeatures in zip(mfccsB, deltasB):\n",
    "    f = np.vstack(spkFeatures)\n",
    "    featuresListB.append(f)\n",
    "\n",
    "# train test split\n",
    "testsize = 5\n",
    "\n",
    "train4A = np.hstack(featuresListA[:-testsize]).T\n",
    "train4B = np.hstack(featuresListB[:-testsize]).T\n",
    "\n",
    "test4A = np.hstack(featuresListA[-testsize:]).T\n",
    "test4B = np.hstack(featuresListB[-testsize:]).T\n",
    "\n",
    "print(train4A.shape)\n",
    "print(train4B.shape)\n",
    "print(test4A.shape)\n",
    "print(test4B.shape)\n",
    "\n",
    "gm4A = GaussianMixture(n_components=1, max_iter=200, n_init=3).fit(train4A)\n",
    "gm4B = GaussianMixture(n_components=1, max_iter=200, n_init=3).fit(train4B)\n",
    "\n",
    "print('Means')\n",
    "print(gm4A.means_.shape)\n",
    "print(gm4B.means_.shape)\n",
    "\n",
    "print('Covariances')\n",
    "print(gm4A.covariances_.shape)\n",
    "print(gm4B.covariances_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahalanobis train\n",
      "A-A:  4.5987666266370555\n",
      "B-A:  9.449667751255243\n",
      "A-B:  11.097810035631527\n",
      "B-B:  4.621195746324019\n",
      "Mahalanobis test\n",
      "A-A:  4.323347672986163\n",
      "B-A:  9.14573714765535\n",
      "A-B:  10.350384495543427\n",
      "B-B:  4.091851017812931\n"
     ]
    }
   ],
   "source": [
    "print('Mahalanobis train')\n",
    "\n",
    "print('A-A: ', meanDist(train4A, gm4A))\n",
    "print('B-A: ', meanDist(train4B, gm4A))\n",
    "print('A-B: ', meanDist(train4A, gm4B))\n",
    "print('B-B: ', meanDist(train4B, gm4B))\n",
    "\n",
    "\n",
    "print('Mahalanobis test')\n",
    "\n",
    "print('A-A: ', meanDist(test4A, gm4A))\n",
    "print('B-A: ', meanDist(test4B, gm4A))\n",
    "print('A-B: ', meanDist(test4A, gm4B))\n",
    "print('B-B: ', meanDist(test4B, gm4B))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2b470cb7f166cc75ffb64c5b7d46eec9af7211564953f54e03e6a7320fb162c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
